{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 05: Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignement\n",
    "  * For the attached data (cleaned data from the 3rd tutorial) try to use linear regression (or ridge regression, if you will) AND decision tree regressor (or boosted tree) applied on features given by PCA.\n",
    "  * Try to select as less as possible features so that the results are comparably good (in terms of RMSLE) to the results obtained in the 3rd tutorial (RMSLE around 0.12).\n",
    "  * Experiment with the feature selection:\n",
    "    * Has removing indicator or discrete features a positive influence?\n",
    "    * Are the first principal components always the best choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import model_selection, linear_model, metrics, preprocessing, feature_selection\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, recall_score\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "data = pd.read_csv('dataHW05.csv', index_col=0)\n",
    "# spliting data to train and testdatasets\n",
    "dtrain, dtest = train_test_split(data, test_size=0.25, random_state=17) #there was 458"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select columns with very low variance to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = 0.001\n",
    "# Id neither help with predictions\n",
    "columns_to_remove = ['Id']\n",
    "columns_to_remove = list(set(list(dtrain.columns[dtrain.var() < treshold]) + columns_to_remove))\n",
    "\n",
    "#print number of columns to delete\n",
    "display(len(columns_to_remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare functions to check linear regression without some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_without_columns(train,validate,columns):\n",
    "    tmp_t = train.drop(columns,axis = 1, errors = 'ignore')\n",
    "    tmp_v = validate.drop(columns,axis = 1, errors = 'ignore')\n",
    "    linreg(tmp_t,tmp_v)\n",
    "    print()\n",
    "    \n",
    "def linreg(train, validate):\n",
    "    # Data prepare\n",
    "    X = train.drop(['SalePrice'], axis = 1, errors = 'ignore')\n",
    "    y = train.SalePrice\n",
    "    Xv = validate.drop(['SalePrice'], axis = 1, errors = 'ignore')\n",
    "    yv = validate.SalePrice   \n",
    "    \n",
    "    # Linear Regression train\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X, y) \n",
    "    \n",
    "    # Print RMSLE\n",
    "    print('Linear regression root mean squared validation error:',\n",
    "          np.sqrt(mean_squared_error(clf.predict(Xv), yv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_without_columns(dtrain,dtest,columns_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add columns, which are not correlated with target value, to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrS = dtrain.drop(columns_to_remove, axis = 1, errors = 'ignore').corr(method='spearman')\n",
    "print(corrS.shape)\n",
    "treshold = 0.01\n",
    "col_S = list(corrS.SalePrice[corrS.SalePrice.abs() < treshold].index)\n",
    "columns_to_remove_S = list(set(columns_to_remove + col_S))\n",
    "print(\"After Spearman\",len(columns_to_remove_S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check T-test for indicator variables and choose some to delete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_pvals = data\\\n",
    "    .drop(columns_to_remove, axis = 1, errors = 'ignore')\\\n",
    "    .select_dtypes(include = ['int64']).columns\\\n",
    "    .to_series()\\\n",
    "    .apply(lambda x: stats.ttest_ind(data.SalePrice[data[x] == 0], data.SalePrice[data[x] == 1], equal_var = False).pvalue)\n",
    "\n",
    "val = 0.5\n",
    "columns_to_remove_tt = list(set(columns_to_remove_S + list(ttest_pvals[ttest_pvals > val].index)))\n",
    "\n",
    "print(len(columns_to_remove_tt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare function to apply wrapper method\n",
    "I have choosen rfecv, because I got better results than with Lasso method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_rfecv(dtrain,dtest):\n",
    "    X = dtrain.drop(['SalePrice'], axis = 1, errors = 'ignore')\n",
    "    y = dtrain.SalePrice\n",
    "\n",
    "    used_columns = X.columns\n",
    "\n",
    "    # define the scorer which will be the RMSE\n",
    "    def scorer(Y, yp):\n",
    "        return np.sqrt(mean_squared_error(Y, yp)) #tu bylo metrics.\n",
    "\n",
    "    # prepare the model\n",
    "    clfM = linear_model.LinearRegression()\n",
    "\n",
    "    # prepare the backward selection algorithm (recursive feature elimination with cross validation)\n",
    "    selector = feature_selection.RFECV(clfM, step=1, cv=4, scoring=metrics.make_scorer(scorer)) # there was 6\n",
    "    # run it\n",
    "    selector = selector.fit(X, y)\n",
    "\n",
    "    # transform result to dataframe\n",
    "    result = pd.DataFrame({'Chosen': selector.support_, 'Ranking': selector.ranking_}, index=list(used_columns))\n",
    "    # columns to leave\n",
    "    columns_to_leave = result[result.Chosen == True].index\n",
    "    # show results\n",
    "    print('Chosen', len(columns_to_leave),'from ', result.Chosen.shape[0], 'features.')\n",
    "    \n",
    "    return dtrain[list(columns_to_leave) + ['SalePrice']],dtest[list(columns_to_leave) + ['SalePrice']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply wrapper method on the data set without columns which I decided to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns_to_remove = columns_to_remove_tt\n",
    "\n",
    "dtrain = dtrain.drop(final_columns_to_remove, axis = 1, errors = 'ignore')\n",
    "dtest = dtest.drop(final_columns_to_remove, axis = 1, errors = 'ignore')\n",
    "\n",
    "#wrapper method return the final result of training and testing data set\n",
    "dtrain_rfecv,dtest_rfecv = wrapper_rfecv(dtrain,dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare function to check linear regression for final data set on which I applied PCA\n",
    "I decided to use just linear regression, because I checked that applying additionally decision tree regressor (or boosted tree) didn't improve my results.\n",
    "\n",
    "After wrapper algorithm there was 232 columns left so I decided to check how PCA will help for maximum 200 first principal columns chosen. I have chosen 200, because where I chosen bigger then results were higher for this few more attempts and it disturbed the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg_with_pca(dtrain,dtest):\n",
    "    q = 205 # number of components\n",
    "\n",
    "    X = dtrain.drop(['SalePrice'], axis = 1, errors = 'ignore')\n",
    "    y = dtrain.SalePrice\n",
    "    Xtest = dtest.drop(['SalePrice'], axis = 1, errors = 'ignore')\n",
    "    ytest = dtest.SalePrice\n",
    "\n",
    "    ####\n",
    "    # without pca\n",
    "    ####\n",
    "    # Linear Regression\n",
    "    clf1 = LinearRegression()\n",
    "    clf1.fit(X, y) \n",
    "\n",
    "    # Print RMSLE\n",
    "    RMSLE_OLS = np.sqrt(mean_squared_error(clf1.predict(Xtest), ytest))\n",
    "    print('Root mean squared logarithmic error:', RMSLE_OLS)\n",
    "    \n",
    "    \n",
    "    #### \n",
    "    # pca with and without scaling\n",
    "    ####\n",
    "    pca = PCA()\n",
    "    pca.fit_transform(X)\n",
    "    X1 = pca.transform(X)\n",
    "    Xtest1 = pca.transform(Xtest)\n",
    "\n",
    "    pca.fit_transform(scale(X))\n",
    "    X2 = pca.transform(scale(X))\n",
    "    Xtest2 = pca.transform(scale(Xtest))\n",
    "    RMSLE = []\n",
    "    RMSLE_scale = []\n",
    "    \n",
    "    rng = np.random.RandomState(1)\n",
    "    \n",
    "    for n in range(1,q):\n",
    "        Xsub1 = X1[:,0:n]\n",
    "        Xsubtest1 = Xtest1[:,0:n]\n",
    "        clf1 = LinearRegression()\n",
    "        clf1.fit(Xsub1, y)\n",
    "        predicted_from_clf1 = clf1.predict(Xsubtest1)\n",
    "        \n",
    "        # save RMSLE\n",
    "        RMSLE.append(np.sqrt(mean_squared_error(predicted_from_clf1, ytest)))        \n",
    "        \n",
    "        Xsub2 = X2[:,0:n]\n",
    "        Xsubtest2 = Xtest2[:,0:n]\n",
    "        clf1 = LinearRegression()\n",
    "        clf1.fit(Xsub2, y) \n",
    "        predicted_from_clf1 = clf1.predict(Xsubtest2)\n",
    "        \n",
    "        # save RMSLE\n",
    "        RMSLE_scale.append(np.sqrt(mean_squared_error(predicted_from_clf1, ytest)))\n",
    "        \n",
    "    plt.subplots(1,1, figsize=(15, 8))\n",
    "    ns = plt.scatter(range(1,q), RMSLE, c='red')\n",
    "    s = plt.scatter(range(1,q), RMSLE_scale, c='green')\n",
    "    plt.title(u\"RMSLE as a function of number of principal components used\")\n",
    "    plt.xlabel(u'number of principal component used')\n",
    "    plt.ylabel('RMSLE')\n",
    "    plt.plot([0, q], [RMSLE_OLS, RMSLE_OLS],'b-')\n",
    "    plt.legend((ns,s),('non-scaled', 'scaled'))\n",
    "\n",
    "    print(\"Number of first principals from pca with minimal RMSLE for not scaled data: \" + str(np.argmin(RMSLE)+1))\n",
    "    print(\"This minimal value for not scaled data: \" + str(RMSLE[np.argmin(RMSLE)]))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of first principals from pca with minimal RMSLE for scaled data: \" + str(np.argmin(RMSLE_scale)+1))\n",
    "    print(\"This minimal value for scaled data: \" + str(RMSLE_scale[np.argmin(RMSLE_scale)]))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally I check result on the data after feature selection and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_with_pca(dtrain_rfecv,dtest_rfecv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that choosing 166 of 232 features by PCA (without scaling the data) let us get the best result - around 0.1224. For feature selection I used methods which helped me to get the best score in the 3rd homework so it is the best result which I can achieve.\n",
    "\n",
    "I can notice that when I have chosen just few first principals with PCA then the result was not good. For 40 first principals with PCA the result get closer to the value of RMSLE for data without PCA, and when we were choosing more and more components than there was an improvement with a result to the best value. But the best value was get not for the all components, so PCA works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
